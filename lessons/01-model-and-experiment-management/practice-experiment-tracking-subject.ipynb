{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Part 4 - Experiment Tracking</h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Tracking and Model Management with MLFlow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to use the MLFlow Tracking API. For simple local uses, the best is to leave the data management to MLFlow and let it store runs, metrics, models and artifacts locally. For more advanced usage, all of this information can be stored in databases. You can find the detailed on MLFlow's documentation [here](https://mlflow.org/docs/latest/tracking.html#scenario-1-mlflow-on-localhost)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring MLFlow\n",
    "\n",
    "MLflow setup:\n",
    "* Tracking server: no\n",
    "* Backend store: local filesystem\n",
    "* Artifacts store: local filesystem\n",
    "\n",
    "The experiments can be explored locally by launching the MLflow UI."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the tracking server URI, where the experiments and runs are going to be logged. We observe it refers to a local path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (2.7.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from mlflow) (8.0.4)\n",
      "Requirement already satisfied: cloudpickle<3 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from mlflow) (2.2.1)\n",
      "Requirement already satisfied: databricks-cli<1,>=0.8.7 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from mlflow) (0.18.0)\n",
      "Requirement already satisfied: entrypoints<1 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from mlflow) (0.4)\n",
      "Requirement already satisfied: gitpython<4,>=2.1.0 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from mlflow) (3.1.41)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from mlflow) (6.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.12.0 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from mlflow) (4.25.1)\n",
      "Requirement already satisfied: pytz<2024 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from mlflow) (2023.3.post1)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from mlflow) (2.31.0)\n",
      "Requirement already satisfied: packaging<24 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from mlflow) (23.1)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<7,>=3.7.0 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from mlflow) (6.0.0)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from mlflow) (0.4.4)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from mlflow) (1.13.1)\n",
      "Requirement already satisfied: docker<7,>=4.0.0 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from mlflow) (6.1.3)\n",
      "Requirement already satisfied: Flask<3 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from mlflow) (2.2.2)\n",
      "Requirement already satisfied: numpy<2 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from mlflow) (1.24.3)\n",
      "Requirement already satisfied: scipy<2 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from mlflow) (1.11.1)\n",
      "Requirement already satisfied: pandas<3 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from mlflow) (2.1.1)\n",
      "Requirement already satisfied: querystring-parser<2 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from mlflow) (1.2.4)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from mlflow) (1.4.39)\n",
      "Requirement already satisfied: scikit-learn<2 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from mlflow) (1.3.1)\n",
      "Requirement already satisfied: pyarrow<14,>=4.0.0 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from mlflow) (11.0.0)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from mlflow) (3.4.1)\n",
      "Requirement already satisfied: matplotlib<4 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from mlflow) (3.7.2)\n",
      "Requirement already satisfied: gunicorn<22 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from mlflow) (21.2.0)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from mlflow) (3.1.2)\n",
      "Requirement already satisfied: Mako in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow) (4.7.1)\n",
      "Requirement already satisfied: pyjwt>=1.7.0 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.4.0)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.2)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.8.10)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.7 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.26.16)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from docker<7,>=4.0.0->mlflow) (0.58.0)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from Flask<3->mlflow) (2.2.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from Flask<3->mlflow) (2.0.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from gitpython<4,>=2.1.0->mlflow) (4.0.11)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from importlib-metadata!=4.7.0,<7,>=3.7.0->mlflow) (3.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from pandas<3->mlflow) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow) (2023.7.22)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (2.2.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (2.0.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow) (5.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URI: 'file:///Users/lauralumbreras/Documents/ESILV/Web%20Scraping/WS%20-%20Env/esilv-mlops/lessons/01-model-and-experiment-management/mlruns'\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this initialization, we can connect create a client to connect to the API and see what experiments are present."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By refering to mlflow's [documentation](https://mlflow.org/docs/latest/python_api/mlflow.client.html), create a client and display a list of the available experiments using the search_experiments function. This function could prove useful later to programatically explore experiments (rather than in the UI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='file:///Users/lauralumbreras/Documents/ESILV/Web%20Scraping/WS%20-%20Env/esilv-mlops/lessons/01-model-and-experiment-management/mlruns/752867516886230624', creation_time=1704910831515, experiment_id='752867516886230624', last_update_time=1704910831515, lifecycle_stage='active', name='/mlflow/LR_Predict_Uber', tags={}>,\n",
       " <Experiment: artifact_location='file:///Users/lauralumbreras/Documents/ESILV/Web%20Scraping/WS%20-%20Env/esilv-mlops/lessons/01-model-and-experiment-management/mlruns', creation_time=1704908656297, experiment_id='325637091980204347', last_update_time=1704908656297, lifecycle_stage='active', name='Timing Uber Experiments', tags={'nlp.framework': 'Spark NLP', 'priority': 'P1', 'version': 'v1'}>,\n",
       " <Experiment: artifact_location='file:///Users/lauralumbreras/Documents/ESILV/Web%20Scraping/WS%20-%20Env/esilv-mlops/lessons/01-model-and-experiment-management/mlruns/561667129408687154', creation_time=1704905285706, experiment_id='561667129408687154', last_update_time=1704905285706, lifecycle_stage='active', name='iris-experiment-1', tags={}>,\n",
       " <Experiment: artifact_location='file:///Users/lauralumbreras/Documents/ESILV/Web%20Scraping/WS%20-%20Env/esilv-mlops/lessons/01-model-and-experiment-management/mlruns/0', creation_time=1704905285696, experiment_id='0', last_update_time=1704905285696, lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "experiments = client.search_experiments()\n",
    "experiments\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is a default experiment for which the runs are stored locally in the mlruns folder."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an experiment and logging a new run"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An experiment is a logical entity regrouping the logs of multiple attempts at solving a same problem, called runs. \\\n",
    "We will now work with the classic sklearn dataset iris. Our goal here is to manage to classify the different iris species. To track our models performance, we will log every attempt as a \"run\" and create a new experiment \"iris-experiment-1\" to regroup them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lookup the mlflow.run and mlflow.start_run functions [here](https://mlflow.org/docs/latest/python_api/mlflow.html?highlight=start_run#mlflow.start_run) to find out how to manage runs.\n",
    "Explore [this part](https://mlflow.org/docs/latest/python_api/mlflow.html) to learn more about the log_params, log_metrics and log_artifact functions. Find out how to log sklearn models [here](https://mlflow.org/docs/latest/python_api/mlflow.sklearn.html])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the following in order to log the parameters, interesting metrics and the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default artifacts URI: 'file:///Users/lauralumbreras/Documents/ESILV/Web%20Scraping/WS%20-%20Env/esilv-mlops/lessons/01-model-and-experiment-management/mlruns/561667129408687154/daa429849900414b8bcadfdc467a5b6e/artifacts'\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlflow.models import infer_signature\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mlflow.set_experiment(\"iris-experiment-1\")\n",
    "\n",
    "# Log a model\n",
    "with mlflow.start_run() as run:\n",
    "    run_id = run.info.run_id\n",
    "    X, y = load_iris(return_X_y=True)\n",
    "    params = {\"C\": 0.1, \"random_state\": 42}\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    model = LogisticRegression(**params).fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "    signature = infer_signature(X, model.predict(X))\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y,y_pred))\n",
    "\n",
    "    mlflow.sklearn.log_model(model, artifact_path=\"models\", signature=signature)\n",
    "\n",
    "    print(f\"default artifacts URI: '{mlflow.get_artifact_uri()}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='file:///Users/lauralumbreras/Documents/ESILV/Web%20Scraping/WS%20-%20Env/esilv-mlops/lessons/01-model-and-experiment-management/mlruns/752867516886230624', creation_time=1704910831515, experiment_id='752867516886230624', last_update_time=1704910831515, lifecycle_stage='active', name='/mlflow/LR_Predict_Uber', tags={}>,\n",
       " <Experiment: artifact_location='file:///Users/lauralumbreras/Documents/ESILV/Web%20Scraping/WS%20-%20Env/esilv-mlops/lessons/01-model-and-experiment-management/mlruns', creation_time=1704908656297, experiment_id='325637091980204347', last_update_time=1704908656297, lifecycle_stage='active', name='Timing Uber Experiments', tags={'nlp.framework': 'Spark NLP', 'priority': 'P1', 'version': 'v1'}>,\n",
       " <Experiment: artifact_location='file:///Users/lauralumbreras/Documents/ESILV/Web%20Scraping/WS%20-%20Env/esilv-mlops/lessons/01-model-and-experiment-management/mlruns/561667129408687154', creation_time=1704905285706, experiment_id='561667129408687154', last_update_time=1704905285706, lifecycle_stage='active', name='iris-experiment-1', tags={}>,\n",
       " <Experiment: artifact_location='file:///Users/lauralumbreras/Documents/ESILV/Web%20Scraping/WS%20-%20Env/esilv-mlops/lessons/01-model-and-experiment-management/mlruns/0', creation_time=1704905285696, experiment_id='0', last_update_time=1704905285696, lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments = client.search_experiments()\n",
    "experiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try running the training script with various parameters to have runs to compare.\n",
    "You can now explore your run(s) using the ui: \\\n",
    "(Paste \"mlflow ui --host 0.0.0.0 --port 5002\" in your terminal, or run the cell below)\n",
    "\n",
    "**N.B.** Make sure you are in the lecture folder and not the repo root!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-12 17:32:12 +0100] [76485] [INFO] Starting gunicorn 21.2.0\n",
      "[2024-01-12 17:32:12 +0100] [76485] [INFO] Listening at: http://0.0.0.0:5002 (76485)\n",
      "[2024-01-12 17:32:12 +0100] [76485] [INFO] Using worker: sync\n",
      "[2024-01-12 17:32:12 +0100] [76486] [INFO] Booting worker with pid: 76486\n",
      "[2024-01-12 17:32:12 +0100] [76487] [INFO] Booting worker with pid: 76487\n",
      "[2024-01-12 17:32:12 +0100] [76488] [INFO] Booting worker with pid: 76488\n",
      "[2024-01-12 17:32:12 +0100] [76489] [INFO] Booting worker with pid: 76489\n",
      "^C\n",
      "[2024-01-12 17:32:51 +0100] [76485] [INFO] Handling signal: int\n",
      "[2024-01-12 17:32:51 +0100] [76489] [INFO] Worker exiting (pid: 76489)\n",
      "[2024-01-12 17:32:51 +0100] [76488] [INFO] Worker exiting (pid: 76488)\n",
      "[2024-01-12 17:32:51 +0100] [76487] [INFO] Worker exiting (pid: 76487)\n",
      "[2024-01-12 17:32:51 +0100] [76486] [INFO] Worker exiting (pid: 76486)\n"
     ]
    }
   ],
   "source": [
    "!mlflow ui --host 0.0.0.0 --port 5002"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will have to kill the cell to continue experimenting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interacting with the model registry"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are satisfied with the last run's model, you can transform the logged model into a registered model. It will be logged in the Model Registry, which makes it easier to use in production and manage versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'iris_lr_model' already exists. Creating a new version of this model...\n",
      "2024/01/12 17:57:18 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: iris_lr_model, version 3\n",
      "Created version '3' of model 'iris_lr_model'.\n"
     ]
    }
   ],
   "source": [
    "# We already have our run id from above. Let's use it to register the model\n",
    "\n",
    "result = mlflow.register_model(f\"runs:/{run_id}/models\", \"iris_lr_model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Case"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will get back to our taxi rides use case: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from typing import List\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (4.7.1)\n",
      "Requirement already satisfied: filelock in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from gdown) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from gdown) (2.31.0)\n",
      "Requirement already satisfied: six in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from gdown) (4.65.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from gdown) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from beautifulsoup4->gdown) (2.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from requests[socks]->gdown) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from requests[socks]->gdown) (2023.7.22)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/lauralumbreras/anaconda3/lib/python3.11/site-packages (from requests[socks]->gdown) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-01.parquet\n",
      "To: /Users/lauralumbreras/Documents/ESILV/Web Scraping/WS - Env/esilv-mlops/data/yellow_tripdata_2021-01.parquet\n",
      "100%|██████████| 21.7M/21.7M [00:01<00:00, 20.0MB/s]\n",
      "Downloading...\n",
      "From: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet\n",
      "To: /Users/lauralumbreras/Documents/ESILV/Web Scraping/WS - Env/esilv-mlops/data/yellow_tripdata_2021-02.parquet\n",
      "100%|██████████| 21.8M/21.8M [00:01<00:00, 21.6MB/s]\n",
      "Downloading...\n",
      "From: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet\n",
      "To: /Users/lauralumbreras/Documents/ESILV/Web Scraping/WS - Env/esilv-mlops/data/yellow_tripdata_2021-03.parquet\n",
      "100%|██████████| 30.0M/30.0M [00:01<00:00, 22.3MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../../data/yellow_tripdata_2021-03.parquet'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "import os\n",
    "\n",
    "DATA_FOLDER = \"../../data\"\n",
    "train_path = f\"{DATA_FOLDER}/yellow_tripdata_2021-01.parquet\"\n",
    "test_path = f\"{DATA_FOLDER}/yellow_tripdata_2021-02.parquet\"\n",
    "predict_path = f\"{DATA_FOLDER}/yellow_tripdata_2021-03.parquet\"\n",
    "\n",
    "\n",
    "if not os.path.exists(DATA_FOLDER):\n",
    "    os.makedirs(DATA_FOLDER)\n",
    "    print(f\"New directory {DATA_FOLDER} created!\")\n",
    "\n",
    "gdown.download(\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-01.parquet\",\n",
    "    train_path,\n",
    "    quiet=False,\n",
    ")\n",
    "gdown.download(\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet\",\n",
    "    test_path,\n",
    "    quiet=False,\n",
    ")\n",
    "gdown.download(\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet\",\n",
    "    predict_path,\n",
    "    quiet=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:30:10</td>\n",
       "      <td>2021-01-01 00:36:12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>142</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.80</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:51:20</td>\n",
       "      <td>2021-01-01 00:52:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>238</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:43:30</td>\n",
       "      <td>2021-01-01 01:11:06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>132</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>51.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:15:48</td>\n",
       "      <td>2021-01-01 00:31:01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>36.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:31:49</td>\n",
       "      <td>2021-01-01 00:48:21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>68</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.36</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2021-01-01 00:30:10   2021-01-01 00:36:12              1.0   \n",
       "1         1  2021-01-01 00:51:20   2021-01-01 00:52:19              1.0   \n",
       "2         1  2021-01-01 00:43:30   2021-01-01 01:11:06              1.0   \n",
       "3         1  2021-01-01 00:15:48   2021-01-01 00:31:01              0.0   \n",
       "4         2  2021-01-01 00:31:49   2021-01-01 00:48:21              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           2.10         1.0                  N           142            43   \n",
       "1           0.20         1.0                  N           238           151   \n",
       "2          14.70         1.0                  N           132           165   \n",
       "3          10.60         1.0                  N           138           132   \n",
       "4           4.94         1.0                  N            68            33   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             2          8.0    3.0      0.5        0.00           0.0   \n",
       "1             2          3.0    0.5      0.5        0.00           0.0   \n",
       "2             1         42.0    0.5      0.5        8.65           0.0   \n",
       "3             1         29.0    0.5      0.5        6.05           0.0   \n",
       "4             1         16.5    0.5      0.5        4.06           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
       "0                    0.3         11.80                   2.5          NaN  \n",
       "1                    0.3          4.30                   0.0          NaN  \n",
       "2                    0.3         51.95                   0.0          NaN  \n",
       "3                    0.3         36.35                   0.0          NaN  \n",
       "4                    0.3         24.36                   2.5          NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(path: str):\n",
    "    return pd.read_parquet(path)\n",
    "\n",
    "\n",
    "train_df = load_data(train_path)\n",
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Prepare the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare the data to make it Machine Learning ready. \\\n",
    "For this, we need to clean it, compute the target (what we want to predict), and compute some features to help the model understand the data better."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1 Compute the target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to predict a taxi trip duration in minutes. Let's compute it as a difference between the drop-off time and the pick-up time for each trip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_target(\n",
    "    df: pd.DataFrame,\n",
    "    pickup_column: str = \"tpep_pickup_datetime\",\n",
    "    dropoff_column: str = \"tpep_dropoff_datetime\",\n",
    ") -> pd.DataFrame:\n",
    "    df[\"duration\"] = df[dropoff_column] - df[pickup_column]\n",
    "    df[\"duration\"] = df[\"duration\"].dt.total_seconds() / 60\n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = compute_target(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.369769e+06\n",
       "mean     1.391168e+01\n",
       "std      1.312006e+02\n",
       "min     -1.350846e+05\n",
       "25%      5.566667e+00\n",
       "50%      9.066667e+00\n",
       "75%      1.461667e+01\n",
       "max      2.881770e+04\n",
       "Name: duration, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"duration\"].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove outliers and reduce the scope to trips between 1 minute and 1 hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_DURATION = 1\n",
    "MAX_DURATION = 60\n",
    "\n",
    "\n",
    "def filter_outliers(df: pd.DataFrame, min_duration: int = 1, max_duration: int = 60) -> pd.DataFrame:\n",
    "    return df[df[\"duration\"].between(min_duration, max_duration)]\n",
    "\n",
    "\n",
    "train_df = filter_outliers(train_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2 Prepare features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2-1 Categorical features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most machine learning models don't work with categorical features. Because of this, they must be transformed so that the ML model can consume them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLS = [\"PUlocationID\", \"DOlocationID\"]\n",
    "\n",
    "\n",
    "def encode_categorical_cols(df: pd.DataFrame, categorical_cols: List[str] = None) -> pd.DataFrame:\n",
    "    if categorical_cols is None:\n",
    "        categorical_cols = [\"PULocationID\", \"DOLocationID\", \"passenger_count\"]\n",
    "    df[categorical_cols] = df[categorical_cols].fillna(-1).astype(\"int\")\n",
    "    df[categorical_cols] = df[categorical_cols].astype(\"str\")\n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = encode_categorical_cols(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_x_y(\n",
    "    df: pd.DataFrame,\n",
    "    categorical_cols: List[str] = None,\n",
    "    dv: DictVectorizer = None,\n",
    "    with_target: bool = True,\n",
    ") -> dict:\n",
    "\n",
    "    if categorical_cols is None:\n",
    "        categorical_cols = [\"PULocationID\", \"DOLocationID\", \"passenger_count\"]\n",
    "    dicts = df[categorical_cols].to_dict(orient=\"records\")\n",
    "\n",
    "    y = None\n",
    "    if with_target:\n",
    "        if dv is None:\n",
    "            dv = DictVectorizer()\n",
    "            dv.fit(dicts)\n",
    "        y = df[\"duration\"].values\n",
    "\n",
    "    x = dv.transform(dicts)\n",
    "    return x, y, dv\n",
    "\n",
    "\n",
    "X_train, y_train, dv = extract_x_y(train_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Train model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train a basic linear regression model to have a baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train: csr_matrix, y_train: np.ndarray):\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x_train, y_train)\n",
    "    return lr\n",
    "\n",
    "\n",
    "model = train_model(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Evaluate model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the model on train and test data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1 On train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.782411952700446"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_duration(input_data: csr_matrix, model: LinearRegression):\n",
    "    return model.predict(input_data)\n",
    "\n",
    "\n",
    "def evaluate_model(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    return mean_squared_error(y_true, y_pred, squared=False)\n",
    "\n",
    "\n",
    "prediction = predict_duration(X_train, model)\n",
    "train_me = evaluate_model(y_train, prediction)\n",
    "train_me"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2 On test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = load_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = compute_target(test_df)\n",
    "test_df = encode_categorical_cols(test_df)\n",
    "X_test, y_test, _ = extract_x_y(test_df, dv=dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.37505101778537"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = predict_duration(X_test, model)\n",
    "test_me = evaluate_model(y_test, y_pred_test)\n",
    "test_me"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Log Model Parameters to MlFlow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all our development functions are built and tested, let's create a training pipeline and log the training parameters, logs and model to MlFlow."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a training flow, log all the important parameters, metrics and model. Try to find what could be important and needs to be logged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lauralumbreras/anaconda3/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Registered model 'LR_Predict_Uber' already exists. Creating a new version of this model...\n",
      "2024/01/12 18:41:12 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: LR_Predict_Uber, version 14\n",
      "Created version '14' of model 'LR_Predict_Uber'.\n"
     ]
    }
   ],
   "source": [
    "# Set the experiment name\n",
    "mlflow_experiment_path = f\"/mlflow/LR_Predict_Uber\"\n",
    "mlflow.set_experiment(mlflow_experiment_path)\n",
    "name=\"LR_Predict_Uber\"\n",
    "\n",
    "# Start a run\n",
    "with mlflow.start_run() as run:\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "    # Set tags for the run\n",
    "    client.set_tag(run.info.run_id, \"01-model-experiment\", \"Predict Uber Duration\")\n",
    "\n",
    "    # Load data\n",
    "    train_df = load_data(train_path)\n",
    "    test_df = load_data(test_path)\n",
    "\n",
    "    # Compute target\n",
    "    train_df = compute_target(train_df)\n",
    "    test_df = compute_target(test_df)\n",
    "\n",
    "    # Filter outliers\n",
    "    train_df = filter_outliers(train_df)\n",
    "\n",
    "    # Encode categorical columns\n",
    "    train_df = encode_categorical_cols(train_df)\n",
    "\n",
    "    # Extract X and y\n",
    "    X_train, y_train, dv = extract_x_y(train_df)\n",
    "\n",
    "    # Train model\n",
    "    model = train_model(X_train, y_train)\n",
    "\n",
    "    # Evaluate model\n",
    "    train_me = evaluate_model(y_train, prediction)\n",
    "\n",
    "    # Evaluate model on test set\n",
    "    test_me = evaluate_model(y_test, y_pred_test)\n",
    "\n",
    "    # Log your model\n",
    "    mlflow.sklearn.log_model(model, \"models\")\n",
    "\n",
    "    # Register your model in mlfow model registry\n",
    "    mlflow.register_model(\"runs:/{}/models\".format(run_id), \"LR_Predict_Uber\")\n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the model is satisfactory, we stage it as production using the appropriate version. This will help us retreiving it for predictions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a mlflow client and use the [mlflow documentation](https://mlflow.org/docs/latest/python_api/mlflow.client.html?highlight=transition_model_version_stage#mlflow.client.MlflowClient.transition_model_version_stage) to stage the appropriate model as being in \"production\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1705078900379, current_stage='Production', description=None, last_updated_timestamp=1705081279158, name='LR_Predict_Uber', run_id='daa429849900414b8bcadfdc467a5b6e', run_link=None, source='models://mlflow/LR_Predict_Uber/production', status='READY', status_message=None, tags={}, user_id=None, version=11>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MlflowClient()\n",
    "production_version=11\n",
    "name= \"LR_Predict_Uber\"\n",
    "desc = \"A new version of the model in Production. This is a test made by Laura\"\n",
    "#src_uri = f\"models:/{mlflow_experiment_path}/production\"\n",
    "\n",
    "# transition model version from None -> staging\n",
    "#mv_src = client.create_model_version(name, src_uri, run.info.run_id)\n",
    "client.transition_model_version_stage(name, version=production_version, stage=\"production\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Predict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use our model to predict on fresh unseen data and forecast what is going to be the duration of a tawi trip depending on trip characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/yellow_tripdata_2021-03.parquet\n",
      "/mlflow/LR_Predict_Uber\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m model_uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels:/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmlflow_experiment_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/production\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m model \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39msklearn\u001b[38;5;241m.\u001b[39mload_model(model_uri)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m     18\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m predict_duration(X_pred, model)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/sklearn/__init__.py:610\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_uri, dst_path)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(model_uri, dst_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    578\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;124;03m    Load a scikit-learn model from a local file or a run.\u001b[39;00m\n\u001b[1;32m    580\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;124;03m        predictions = sk_model.predict(pandas_df)\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 610\u001b[0m     local_model_path \u001b[38;5;241m=\u001b[39m _download_artifact_from_uri(artifact_uri\u001b[38;5;241m=\u001b[39mmodel_uri, output_path\u001b[38;5;241m=\u001b[39mdst_path)\n\u001b[1;32m    611\u001b[0m     flavor_conf \u001b[38;5;241m=\u001b[39m _get_flavor_configuration(model_path\u001b[38;5;241m=\u001b[39mlocal_model_path, flavor_name\u001b[38;5;241m=\u001b[39mFLAVOR_NAME)\n\u001b[1;32m    612\u001b[0m     _add_code_from_conf_to_system_path(local_model_path, flavor_conf)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/tracking/artifact_utils.py:100\u001b[0m, in \u001b[0;36m_download_artifact_from_uri\u001b[0;34m(artifact_uri, output_path)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m:param artifact_uri: The *absolute* URI of the artifact to download.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m:param output_path: The local filesystem path to which to download the artifact. If unspecified,\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m                    a local output path will be created.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m root_uri, artifact_path \u001b[38;5;241m=\u001b[39m _get_root_uri_and_artifact_path(artifact_uri)\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m get_artifact_repository(artifact_uri\u001b[38;5;241m=\u001b[39mroot_uri)\u001b[38;5;241m.\u001b[39mdownload_artifacts(\n\u001b[1;32m    101\u001b[0m     artifact_path\u001b[38;5;241m=\u001b[39martifact_path, dst_path\u001b[38;5;241m=\u001b[39moutput_path\n\u001b[1;32m    102\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/store/artifact/artifact_repository_registry.py:115\u001b[0m, in \u001b[0;36mget_artifact_repository\u001b[0;34m(artifact_uri)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_artifact_repository\u001b[39m(artifact_uri):\n\u001b[1;32m    106\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get an artifact repository from the registry based on the scheme of artifact_uri\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    :param artifact_uri: The artifact store URI. This URI is used to select which artifact\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m             requirements.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _artifact_repository_registry\u001b[38;5;241m.\u001b[39mget_artifact_repository(artifact_uri)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/store/artifact/artifact_repository_registry.py:72\u001b[0m, in \u001b[0;36mArtifactRepositoryRegistry.get_artifact_repository\u001b[0;34m(self, artifact_uri)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repository \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find a registered artifact repository for: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00martifact_uri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently registered schemes are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registry\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m     )\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repository(artifact_uri)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/store/artifact/models_artifact_repo.py:45\u001b[0m, in \u001b[0;36mModelsArtifactRepository.__init__\u001b[0;34m(self, artifact_uri)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m     uri \u001b[38;5;241m=\u001b[39m ModelsArtifactRepository\u001b[38;5;241m.\u001b[39mget_underlying_uri(artifact_uri)\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepo \u001b[38;5;241m=\u001b[39m get_artifact_repository(uri)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/store/artifact/artifact_repository_registry.py:115\u001b[0m, in \u001b[0;36mget_artifact_repository\u001b[0;34m(artifact_uri)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_artifact_repository\u001b[39m(artifact_uri):\n\u001b[1;32m    106\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get an artifact repository from the registry based on the scheme of artifact_uri\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    :param artifact_uri: The artifact store URI. This URI is used to select which artifact\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m             requirements.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _artifact_repository_registry\u001b[38;5;241m.\u001b[39mget_artifact_repository(artifact_uri)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/store/artifact/artifact_repository_registry.py:72\u001b[0m, in \u001b[0;36mArtifactRepositoryRegistry.get_artifact_repository\u001b[0;34m(self, artifact_uri)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repository \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find a registered artifact repository for: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00martifact_uri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently registered schemes are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registry\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m     )\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repository(artifact_uri)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/store/artifact/models_artifact_repo.py:45\u001b[0m, in \u001b[0;36mModelsArtifactRepository.__init__\u001b[0;34m(self, artifact_uri)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m     uri \u001b[38;5;241m=\u001b[39m ModelsArtifactRepository\u001b[38;5;241m.\u001b[39mget_underlying_uri(artifact_uri)\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepo \u001b[38;5;241m=\u001b[39m get_artifact_repository(uri)\n",
      "    \u001b[0;31m[... skipping similar frames: get_artifact_repository at line 115 (735 times), ArtifactRepositoryRegistry.get_artifact_repository at line 72 (735 times), ModelsArtifactRepository.__init__ at line 45 (734 times)]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/store/artifact/models_artifact_repo.py:45\u001b[0m, in \u001b[0;36mModelsArtifactRepository.__init__\u001b[0;34m(self, artifact_uri)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m     uri \u001b[38;5;241m=\u001b[39m ModelsArtifactRepository\u001b[38;5;241m.\u001b[39mget_underlying_uri(artifact_uri)\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepo \u001b[38;5;241m=\u001b[39m get_artifact_repository(uri)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/store/artifact/artifact_repository_registry.py:115\u001b[0m, in \u001b[0;36mget_artifact_repository\u001b[0;34m(artifact_uri)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_artifact_repository\u001b[39m(artifact_uri):\n\u001b[1;32m    106\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get an artifact repository from the registry based on the scheme of artifact_uri\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    :param artifact_uri: The artifact store URI. This URI is used to select which artifact\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m             requirements.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _artifact_repository_registry\u001b[38;5;241m.\u001b[39mget_artifact_repository(artifact_uri)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/store/artifact/artifact_repository_registry.py:72\u001b[0m, in \u001b[0;36mArtifactRepositoryRegistry.get_artifact_repository\u001b[0;34m(self, artifact_uri)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repository \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find a registered artifact repository for: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00martifact_uri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently registered schemes are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registry\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m     )\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repository(artifact_uri)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/store/artifact/models_artifact_repo.py:44\u001b[0m, in \u001b[0;36mModelsArtifactRepository.__init__\u001b[0;34m(self, artifact_uri)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepo \u001b[38;5;241m=\u001b[39m DatabricksModelsArtifactRepository(artifact_uri)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     uri \u001b[38;5;241m=\u001b[39m ModelsArtifactRepository\u001b[38;5;241m.\u001b[39mget_underlying_uri(artifact_uri)\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepo \u001b[38;5;241m=\u001b[39m get_artifact_repository(uri)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/store/artifact/models_artifact_repo.py:78\u001b[0m, in \u001b[0;36mModelsArtifactRepository.get_underlying_uri\u001b[0;34m(uri)\u001b[0m\n\u001b[1;32m     74\u001b[0m databricks_profile_uri \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     75\u001b[0m     get_databricks_profile_uri_from_artifact_uri(uri) \u001b[38;5;129;01mor\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mget_registry_uri()\n\u001b[1;32m     76\u001b[0m )\n\u001b[1;32m     77\u001b[0m client \u001b[38;5;241m=\u001b[39m MlflowClient(registry_uri\u001b[38;5;241m=\u001b[39mdatabricks_profile_uri)\n\u001b[0;32m---> 78\u001b[0m (name, version) \u001b[38;5;241m=\u001b[39m get_model_name_and_version(client, uri)\n\u001b[1;32m     79\u001b[0m download_uri \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mget_model_version_download_uri(name, version)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m add_databricks_profile_info_to_artifact_uri(download_uri, databricks_profile_uri)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/store/artifact/utils/models.py:94\u001b[0m, in \u001b[0;36mget_model_name_and_version\u001b[0;34m(client, models_uri)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_alias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_name, client\u001b[38;5;241m.\u001b[39mget_model_version_by_alias(model_name, model_alias)\u001b[38;5;241m.\u001b[39mversion\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_name, \u001b[38;5;28mstr\u001b[39m(_get_latest_model_version(client, model_name, model_stage))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/store/artifact/utils/models.py:32\u001b[0m, in \u001b[0;36m_get_latest_model_version\u001b[0;34m(client, name, stage)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_latest_model_version\u001b[39m(client, name, stage):\n\u001b[1;32m     28\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m    Returns the latest version of the stage if stage is not None. Otherwise return the latest of all\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    versions.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     latest \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mget_latest_versions(name, \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m stage \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m [stage])\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(latest) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     34\u001b[0m         stage_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stage \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and stage \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/tracking/client.py:2429\u001b[0m, in \u001b[0;36mMlflowClient.get_latest_versions\u001b[0;34m(self, name, stages)\u001b[0m\n\u001b[1;32m   2357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_latest_versions\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m, stages: List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[ModelVersion]:\n\u001b[1;32m   2358\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2359\u001b[0m \u001b[38;5;124;03m    Latest version models for each requests stage. If no ``stages`` provided, returns the\u001b[39;00m\n\u001b[1;32m   2360\u001b[0m \u001b[38;5;124;03m    latest version for each stage.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2427\u001b[0m \u001b[38;5;124;03m        current_stage: None\u001b[39;00m\n\u001b[1;32m   2428\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2429\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_registry_client()\u001b[38;5;241m.\u001b[39mget_latest_versions(name, stages)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/tracking/_model_registry/client.py:139\u001b[0m, in \u001b[0;36mModelRegistryClient.get_latest_versions\u001b[0;34m(self, name, stages)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_latest_versions\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, stages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Latest version models for each requests stage. If no ``stages`` provided, returns the\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    latest version for each stage.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m    :return: List of :py:class:`mlflow.entities.model_registry.ModelVersion` objects.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore\u001b[38;5;241m.\u001b[39mget_latest_versions(name, stages)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/store/model_registry/file_store.py:366\u001b[0m, in \u001b[0;36mFileStore.get_latest_versions\u001b[0;34m(self, name, stages)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exists(registered_model_path):\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRegistered Model with name=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    364\u001b[0m         RESOURCE_DOES_NOT_EXIST,\n\u001b[1;32m    365\u001b[0m     )\n\u001b[0;32m--> 366\u001b[0m model_versions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_list_model_versions_under_path(registered_model_path)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stages \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(stages) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    368\u001b[0m     expected_stages \u001b[38;5;241m=\u001b[39m {get_canonical_stage(stage) \u001b[38;5;28;01mfor\u001b[39;00m stage \u001b[38;5;129;01min\u001b[39;00m ALL_STAGES}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/store/model_registry/file_store.py:732\u001b[0m, in \u001b[0;36mFileStore._list_model_versions_under_path\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    725\u001b[0m model_version_dirs \u001b[38;5;241m=\u001b[39m list_all(\n\u001b[1;32m    726\u001b[0m     path,\n\u001b[1;32m    727\u001b[0m     filter_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(x)\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(x))\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion-\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    729\u001b[0m     full_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    730\u001b[0m )\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m directory \u001b[38;5;129;01min\u001b[39;00m model_version_dirs:\n\u001b[0;32m--> 732\u001b[0m     model_versions\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_model_version_from_dir(directory))\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_versions\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/store/model_registry/file_store.py:504\u001b[0m, in \u001b[0;36mFileStore._get_model_version_from_dir\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_model_version_from_dir\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory):\n\u001b[0;32m--> 504\u001b[0m     meta \u001b[38;5;241m=\u001b[39m FileStore\u001b[38;5;241m.\u001b[39m_read_yaml(directory, FileStore\u001b[38;5;241m.\u001b[39mMETA_DATA_FILE_NAME)\n\u001b[1;32m    505\u001b[0m     meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_model_version_tags_from_dir(directory)\n\u001b[1;32m    506\u001b[0m     meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maliases\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_model_version_aliases(directory)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/store/model_registry/file_store.py:906\u001b[0m, in \u001b[0;36mFileStore._read_yaml\u001b[0;34m(root, file_name, retries)\u001b[0m\n\u001b[1;32m    903\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.1\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m3\u001b[39m \u001b[38;5;241m-\u001b[39m attempts_remaining))\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _read_helper(root, file_name, attempts_remaining \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 906\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read_helper(root, file_name, attempts_remaining\u001b[38;5;241m=\u001b[39mretries)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/store/model_registry/file_store.py:899\u001b[0m, in \u001b[0;36mFileStore._read_yaml.<locals>._read_helper\u001b[0;34m(root, file_name, attempts_remaining)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_helper\u001b[39m(root, file_name, attempts_remaining\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m--> 899\u001b[0m     result \u001b[38;5;241m=\u001b[39m read_yaml(root, file_name)\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m attempts_remaining \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    901\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/utils/file_utils.py:290\u001b[0m, in \u001b[0;36mread_yaml\u001b[0;34m(root, file_name)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m yaml\u001b[38;5;241m.\u001b[39mload(yaml_file, Loader\u001b[38;5;241m=\u001b[39mYamlSafeLoader)\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/utils/file_utils.py:288\u001b[0m, in \u001b[0;36mread_yaml\u001b[0;34m(root, file_name)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mopen(file_path, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39mENCODING) \u001b[38;5;28;01mas\u001b[39;00m yaml_file:\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m yaml\u001b[38;5;241m.\u001b[39mload(yaml_file, Loader\u001b[38;5;241m=\u001b[39mYamlSafeLoader)\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/yaml/__init__.py:81\u001b[0m, in \u001b[0;36mload\u001b[0;34m(stream, Loader)\u001b[0m\n\u001b[1;32m     79\u001b[0m loader \u001b[38;5;241m=\u001b[39m Loader(stream)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loader\u001b[38;5;241m.\u001b[39mget_single_data()\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     loader\u001b[38;5;241m.\u001b[39mdispose()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/yaml/constructor.py:51\u001b[0m, in \u001b[0;36mBaseConstructor.get_single_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_single_node()\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstruct_document(node)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/yaml/constructor.py:60\u001b[0m, in \u001b[0;36mBaseConstructor.construct_document\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_generators \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m generator \u001b[38;5;129;01min\u001b[39;00m state_generators:\n\u001b[0;32m---> 60\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m dummy \u001b[38;5;129;01min\u001b[39;00m generator:\n\u001b[1;32m     61\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstructed_objects \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/yaml/constructor.py:413\u001b[0m, in \u001b[0;36mSafeConstructor.construct_yaml_map\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    411\u001b[0m data \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m data\n\u001b[0;32m--> 413\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstruct_mapping(node)\n\u001b[1;32m    414\u001b[0m data\u001b[38;5;241m.\u001b[39mupdate(value)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/yaml/constructor.py:218\u001b[0m, in \u001b[0;36mSafeConstructor.construct_mapping\u001b[0;34m(self, node, deep)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, MappingNode):\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten_mapping(node)\n\u001b[0;32m--> 218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mconstruct_mapping(node, deep\u001b[38;5;241m=\u001b[39mdeep)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/yaml/constructor.py:139\u001b[0m, in \u001b[0;36mBaseConstructor.construct_mapping\u001b[0;34m(self, node, deep)\u001b[0m\n\u001b[1;32m    137\u001b[0m mapping \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key_node, value_node \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39mvalue:\n\u001b[0;32m--> 139\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstruct_object(key_node, deep\u001b[38;5;241m=\u001b[39mdeep)\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mHashable):\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConstructorError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile constructing a mapping\u001b[39m\u001b[38;5;124m\"\u001b[39m, node\u001b[38;5;241m.\u001b[39mstart_mark,\n\u001b[1;32m    142\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound unhashable key\u001b[39m\u001b[38;5;124m\"\u001b[39m, key_node\u001b[38;5;241m.\u001b[39mstart_mark)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/yaml/constructor.py:100\u001b[0m, in \u001b[0;36mBaseConstructor.construct_object\u001b[0;34m(self, node, deep)\u001b[0m\n\u001b[1;32m     98\u001b[0m             constructor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39mconstruct_mapping\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tag_suffix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 100\u001b[0m     data \u001b[38;5;241m=\u001b[39m constructor(\u001b[38;5;28mself\u001b[39m, node)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     data \u001b[38;5;241m=\u001b[39m constructor(\u001b[38;5;28mself\u001b[39m, tag_suffix, node)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/yaml/constructor.py:403\u001b[0m, in \u001b[0;36mSafeConstructor.construct_yaml_str\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstruct_yaml_str\u001b[39m(\u001b[38;5;28mself\u001b[39m, node):\n\u001b[0;32m--> 403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstruct_scalar(node)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/yaml/constructor.py:178\u001b[0m, in \u001b[0;36mSafeConstructor.construct_scalar\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key_node\u001b[38;5;241m.\u001b[39mtag \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtag:yaml.org,2002:value\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    177\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstruct_scalar(value_node)\n\u001b[0;32m--> 178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mconstruct_scalar(node)\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "# Load prediction data\n",
    "predict_df = load_data(predict_path)\n",
    "print(predict_path)\n",
    "print(mlflow_experiment_path)\n",
    "\n",
    "# Apply feature engineering\n",
    "predict_df = encode_categorical_cols(predict_df)\n",
    "X_pred, _, _ = extract_x_y(predict_df, dv=dv, with_target=False)\n",
    "\n",
    "# Load production model\n",
    "print(\"1\")\n",
    "model_uri = f\"models:/{mlflow_experiment_path}/production\"\n",
    "print(\"2\")\n",
    "\n",
    "model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = predict_duration(X_pred, model)\n",
    "y_pred\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - To go further"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you managed to go this far, you can try solving the use case using an other regression model like [XGBoost](https://xgboost.readthedocs.io/en/stable/) for instance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6008d53778f36635ba13ef5eb2b9da68b78b7e259c3135e672f352dc09e97e14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
